{"version":3,"sources":["needle.js","querystring.js","multipart.js","auth.js","cookies.js","parsers.js","decoder.js","utils.js","../package.json"],"names":[],"mappings":";;;;;;;AAAA;AACA;AACA;AACA,ACHA;ADIA,ACHA;ADIA,ACHA;ACFA,AFMA,ACHA;ACFA,AFMA,ACHA;ACFA,AFMA,ACHA;AELA,ADGA,AFMA,ACHA;AELA,ADGA,AFMA,ACHA;AELA,ADGA,AFMA,ACHA;AELA,ACHA,AFMA,AFMA,ACHA;AELA,ACHA,AFMA,AFMA,ACHA;AELA,ACHA,AFMA,AFMA,ACHA;AELA,ACHA,AFMA,AFMA,AKfA,AJYA;AELA,ACHA,AFMA,AFMA,AKfA,AJYA;AELA,ACHA,AFMA,AFMA,AKfA,AJYA;AELA,ACHA,AENA,AJYA,AFMA,AKfA,AJYA;AELA,ACHA,AENA,AJYA,AFMA,AKfA,AJYA;AELA,ACHA,AENA,AJYA,AFMA,AKfA,AJYA;AELA,ACHA,AENA,AJYA,AFMA,AKfA,AJYA,AMlBA;AJaA,ACHA,AENA,AJYA,AFMA,AKfA,AJYA,AMlBA;AJaA,ACHA,AENA,AJYA,AFMA,AKfA,AJYA,AMlBA;ACFA,ALeA,ACHA,AENA,AJYA,AFMA,AKfA,AJYA,AMlBA;ACFA,ALeA,ACHA,AENA,AJYA,AFMA,AKfA,AJYA,AMlBA;ACFA,ALeA,ACHA,AENA,AJYA,AFMA,AKfA,AJYA,AMlBA;ACFA,ALeA,ACHA,AENA,AJYA,AFMA,AKfA,AJYA,AMlBA;ACFA,ALeA,ACHA,AENA,AJYA,AFMA,AKfA,AJYA,AMlBA;ACFA,ALeA,ACHA,AENA,AJYA,AFMA,AKfA,AJYA,AMlBA;ACFA,ALeA,ACHA,AENA,AJYA,AFMA,AKfA,AJYA,AMlBA;ACFA,ALeA,ACHA,AENA,AJYA,AFMA,AKfA,AJYA,AMlBA;ACFA,ALeA,ACHA,AENA,AJYA,AFMA,AKfA,AJYA,AMlBA;ACFA,ALeA,ACHA,AENA,AJYA,AFMA,AKfA,AJYA,AMlBA;ACFA,ALeA,ACHA,AENA,AJYA,AFMA,AKfA,AJYA,AMlBA;ACFA,ALeA,ACHA,AENA,AJYA,AFMA,AKfA,AJYA,AMlBA;ACFA,ALeA,ACHA,AENA,AJYA,AFMA,AKfA,AJYA,AMlBA;ACFA,ALeA,ACHA,AENA,AJYA,AFMA,AKfA,AJYA,AMlBA;ACFA,ALeA,ACHA,AENA,AJYA,AFMA,AKfA,AJYA,AMlBA;ACFA,ALeA,ACHA,AENA,AJYA,AFMA,AKfA,AJYA,AMlBA;ACFA,ALeA,ACHA,AENA,AJYA,AFMA,AKfA,AJYA,AMlBA;ACFA,ALeA,ACHA,AENA,AJYA,AFMA,AKfA,AJYA,AMlBA;ACFA,ALeA,ACHA,AENA,AJYA,AFMA,AKfA,AJYA,AMlBA;ACFA,ALeA,ACHA,AENA,AJYA,AFMA,AKfA,AJYA,AMlBA;ACFA,ALeA,ACHA,AENA,AJYA,AFMA,AKfA,AJYA,AMlBA;ACFA,ALeA,ACHA,AENA,AJYA,AFMA,AKfA,AJYA,AMlBA;ACFA,ALeA,ACHA,AENA,AJYA,AFMA,AKfA,AJYA,AMlBA;ACFA,ALeA,ACHA,AENA,AJYA,AFMA,AKfA,AJYA,AMlBA;ACFA,ALeA,ACHA,AENA,AJYA,AFMA,AKfA,AJYA,AMlBA;ACFA,ALeA,ACHA,AENA,AJYA,AFMA,AKfA,AJYA,AMlBA;ACFA,ALeA,ACHA,AENA,AJYA,AFMA,AKfA,AJYA,AMlBA;ACFA,ALeA,ACHA,AENA,AJYA,AFMA,AKfA,AJYA,AMlBA;ACFA,ALeA,ACHA,AENA,AJYA,AFMA,AKfA,AJYA,AMlBA;ACFA,ALeA,ACHA,AENA,AJYA,AFMA,AKfA,AENA;ACFA,ALeA,ACHA,AENA,AJYA,AFMA,AKfA,AENA;ACFA,ALeA,ACHA,AENA,AJYA,AFMA,AKfA,AENA;ACFA,ALeA,ACHA,AENA,AJYA,AFMA,AKfA,AENA;ACFA,ALeA,ACHA,AENA,AJYA,AFMA,AKfA,AENA;ACFA,ALeA,ACHA,AENA,AJYA,AFMA,AKfA,AENA;ACFA,ALeA,ACHA,AENA,AJYA,AFMA,AKfA,AENA;ACFA,ALeA,ACHA,AENA,AJYA,AFMA,AKfA,AENA;ACFA,ALeA,ACHA,AENA,AJYA,AFMA,AKfA,AENA;ACFA,ALeA,ACHA,AENA,AJYA,AFMA,AKfA,AENA;ACFA,ALeA,ACHA,AENA,AJYA,AFMA,AKfA,AENA;ACFA,ALeA,ACHA,AENA,AJYA,AFMA,AKfA,AENA;ACFA,ALeA,ACHA,AENA,AJYA,AFMA,AKfA,AENA;ACFA,ALeA,ACHA,AENA,AJYA,AFMA,AKfA,AENA;ACFA,ALeA,ACHA,AENA,AJYA,AFMA,AKfA,AENA;ACFA,ALeA,ACHA,AENA,AJYA,AFMA,AKfA,AENA;ACFA,ALeA,ACHA,AENA,AJYA,AFMA,AKfA,AENA;ACFA,ALeA,ACHA,AENA,AJYA,AFMA,AKfA,AENA;ACFA,ALeA,ACHA,AENA,AJYA,AFMA,AKfA,AENA;ACFA,ALeA,ACHA,AENA,AJYA,AFMA,AKfA,AENA;ACFA,ALeA,ACHA,AENA,AJYA,AFMA,AKfA,AENA;ACFA,ALeA,ACHA,AENA,AJYA,AFMA,AKfA,AENA;ACFA,ALeA,ACHA,AENA,AJYA,AFMA,AKfA,AENA;ACFA,ALeA,ACHA,AENA,AJYA,AFMA,AKfA,AENA;ACFA,ALeA,ACHA,AENA,AJYA,AFMA,AKfA,AENA;ACFA,ALeA,ACHA,AENA,AJYA,AFMA,AKfA,AENA;ACFA,ALeA,ACHA,AENA,AJYA,AFMA,AKfA,AENA;ACFA,ALeA,ACHA,AENA,AJYA,AFMA,AKfA,AENA;ACFA,ALeA,ACHA,AFMA,AFMA,AKfA,AENA;ACFA,ALeA,ACHA,AFMA,AFMA,AKfA,AENA;ACFA,ALeA,ACHA,AFMA,AFMA,AKfA,AENA;ACFA,ALeA,ACHA,AFMA,AFMA,AKfA,AENA;ACFA,ALeA,ACHA,AFMA,AFMA,AKfA,AENA;ACFA,ALeA,ACHA,AFMA,AFMA,AKfA,AENA;ACFA,ALeA,ACHA,AFMA,AFMA,AKfA,AENA;ACFA,ALeA,ACHA,AFMA,AFMA,AKfA,AENA;ACFA,ALeA,ACHA,AFMA,AFMA,AKfA,AENA;ACFA,ALeA,ACHA,AFMA,AFMA,AKfA,AENA;ACFA,ALeA,ACHA,AFMA,AFMA,AKfA,AENA;ACFA,ALeA,ADGA,AFMA,AKfA,AENA;ACFA,ALeA,ADGA,AFMA,AKfA,AENA;ACFA,ALeA,ADGA,AFMA,AKfA,AENA;AJaA,ADGA,AFMA,AKfA,AENA;AJaA,ADGA,AFMA,AKfA,AENA;AJaA,ADGA,AFMA,AKfA,AENA;AJaA,ADGA,AFMA,AKfA,AENA;AJaA,ADGA,AFMA,AKfA,AENA;AJaA,ADGA,AFMA,AKfA,AENA;AJaA,ADGA,AFMA,AKfA,AENA;AJaA,ADGA,AFMA,AKfA,AENA;AJaA,ADGA,AFMA,AKfA,AENA;AJaA,ADGA,AFMA,AKfA,AENA;AJaA,AHSA,AKfA,AENA;AJaA,AHSA,AKfA,AENA;AJaA,AHSA,AKfA,AENA;AJaA,AHSA,AKfA,AENA;AJaA,AHSA,AKfA,AENA;AJaA,AHSA,AKfA,AENA;AJaA,AHSA,AKfA,AENA;AJaA,AHSA,AKfA,AENA;AJaA,AHSA,AKfA,AENA;AJaA,AHSA,AKfA,AENA;AJaA,AHSA,AKfA,AENA;AJaA,AHSA,AKfA,AENA;AJaA,AHSA,AKfA,AENA;AJaA,AHSA,AKfA,AENA;AJaA,AHSA,AKfA,AENA;AJaA,AHSA,AKfA,AENA;APsBA,AKfA,AENA;APsBA,AKfA,AENA;APsBA,AKfA,AENA;APsBA,AKfA,AENA;APsBA,AKfA,AENA;APsBA,AKfA,AENA;APsBA,AKfA,AENA;APsBA,AKfA,AENA;APsBA,AKfA,AENA;APsBA,AKfA,AENA;APsBA,AKfA,AENA;APsBA,AKfA;ALgBA,AKfA;ALgBA,AKfA;ALgBA,AKfA;ALgBA,AKfA;ALgBA,AKfA;ALgBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA","file":"index.js","sourcesContent":["//////////////////////////////////////////\n// Needle -- HTTP Client for Node.js\n// Written by Tom√°s Pollak <tomas@forkhq.com>\n// (c) 2012-2023 - Fork Ltd.\n// MIT Licensed\n//////////////////////////////////////////\n\nvar fs          = require('fs'),\n    http        = require('http'),\n    https       = require('https'),\n    url         = require('url'),\n    stream      = require('stream'),\n    debug       = require('util').debuglog('needle'),\n    stringify   = require('./querystring').build,\n    multipart   = require('./multipart'),\n    auth        = require('./auth'),\n    cookies     = require('./cookies'),\n    parsers     = require('./parsers'),\n    decoder     = require('./decoder'),\n    utils       = require('./utils');\n\n//////////////////////////////////////////\n// variabilia\n\nvar version     = require('../package.json').version;\n\nvar user_agent  = 'Needle/' + version;\nuser_agent     += ' (Node.js ' + process.version + '; ' + process.platform + ' ' + process.arch + ')';\n\nvar tls_options = 'pfx key passphrase cert ca ciphers rejectUnauthorized secureProtocol checkServerIdentity family';\n\n// older versions of node (< 0.11.4) prevent the runtime from exiting\n// because of connections in keep-alive state. so if this is the case\n// we'll default new requests to set a Connection: close header.\nvar close_by_default = !http.Agent || http.Agent.defaultMaxSockets != Infinity;\n\n// see if we have Object.assign. otherwise fall back to util._extend\nvar extend = Object.assign ? Object.assign : require('util')._extend;\n\n// these are the status codes that Needle interprets as redirects.\nvar redirect_codes = [301, 302, 303, 307, 308];\n\n//////////////////////////////////////////\n// decompressors for gzip/deflate/br bodies\n\nfunction bind_opts(fn, options) {\n  return fn.bind(null, options);\n}\n\nvar decompressors = {};\n\ntry {\n\n  var zlib = require('zlib');\n\n  // Enable Z_SYNC_FLUSH to avoid Z_BUF_ERROR errors (Node PR #2595)\n  var zlib_options = {\n    flush: zlib.Z_SYNC_FLUSH,\n    finishFlush: zlib.Z_SYNC_FLUSH\n  };\n\n  var br_options = {\n    flush: zlib.BROTLI_OPERATION_FLUSH,\n    finishFlush: zlib.BROTLI_OPERATION_FLUSH\n  };\n\n  decompressors['x-deflate'] = bind_opts(zlib.Inflate, zlib_options);\n  decompressors['deflate']   = bind_opts(zlib.Inflate, zlib_options);\n  decompressors['x-gzip']    = bind_opts(zlib.Gunzip, zlib_options);\n  decompressors['gzip']      = bind_opts(zlib.Gunzip, zlib_options);\n  if (typeof zlib.BrotliDecompress === 'function') {\n    decompressors['br']      = bind_opts(zlib.BrotliDecompress, br_options);\n  }\n\n} catch(e) { /* zlib not available */ }\n\n//////////////////////////////////////////\n// options and aliases\n\nvar defaults = {\n  // data\n  boundary                : '--------------------NODENEEDLEHTTPCLIENT',\n  encoding                : 'utf8',\n  parse_response          : 'all', // same as true. valid options: 'json', 'xml' or false/null\n  proxy                   : null,\n\n  // agent & headers\n  agent                   : null,\n  headers                 : {},\n  accept                  : '*/*',\n  user_agent              : user_agent,\n\n  // numbers\n  open_timeout            : 10000,\n  response_timeout        : 0,\n  read_timeout            : 0,\n  follow_max              : 0,\n  stream_length           : -1,\n\n  // abort signal\n  signal                  : null,\n\n  // booleans\n  compressed              : false,\n  decode_response         : true,\n  parse_cookies           : true,\n  follow_set_cookies      : false,\n  follow_set_referer      : false,\n  follow_keep_method      : false,\n  follow_if_same_host     : false,\n  follow_if_same_protocol : false,\n  follow_if_same_location : false,\n  use_proxy_from_env_var  : true\n}\n\nvar aliased = {\n  options: {\n    decode  : 'decode_response',\n    parse   : 'parse_response',\n    timeout : 'open_timeout',\n    follow  : 'follow_max'\n  },\n  inverted: {}\n}\n\n// only once, invert aliased keys so we can get passed options.\nObject.keys(aliased.options).map(function(k) {\n  var value = aliased.options[k];\n  aliased.inverted[value] = k;\n});\n\n//////////////////////////////////////////\n// helpers\n\nfunction keys_by_type(type) {\n  return Object.keys(defaults).map(function(el) {\n    if (defaults[el] !== null && defaults[el].constructor == type)\n      return el;\n  }).filter(function(el) { return el })\n}\n\n//////////////////////////////////////////\n// the main act\n\nfunction Needle(method, uri, data, options, callback) {\n  // if (!(this instanceof Needle)) {\n  //   return new Needle(method, uri, data, options, callback);\n  // }\n\n  if (typeof uri !== 'string')\n    throw new TypeError('URL must be a string, not ' + uri);\n\n  this.method   = method.toLowerCase();\n  this.uri      = uri;\n  this.data     = data;\n\n  if (typeof options == 'function') {\n    this.callback = options;\n    this.options  = {};\n  } else {\n    this.callback = callback;\n    this.options  = options;\n  }\n\n}\n\nNeedle.prototype.setup = function(uri, options) {\n\n  function get_option(key, fallback) {\n    // if original is in options, return that value\n    if (typeof options[key] != 'undefined') return options[key];\n\n    // otherwise, return value from alias or fallback/undefined\n    return typeof options[aliased.inverted[key]] != 'undefined'\n                ? options[aliased.inverted[key]] : fallback;\n  }\n\n  function check_value(expected, key) {\n    var value = get_option(key),\n        type  = typeof value;\n\n    if (type != 'undefined' && type != expected)\n      throw new TypeError(type + ' received for ' + key + ', but expected a ' + expected);\n\n    return (type == expected) ? value : defaults[key];\n  }\n\n  //////////////////////////////////////////////////\n  // the basics\n\n  var config = {\n    http_opts : {\n      agent: get_option('agent', defaults.agent),\n      localAddress: get_option('localAddress', undefined),\n      lookup: get_option('lookup', undefined),\n      signal: get_option('signal', defaults.signal)\n    }, // passed later to http.request() directly\n    headers   : {},\n    output    : options.output,\n    proxy     : get_option('proxy', defaults.proxy),\n    parser    : get_option('parse_response', defaults.parse_response),\n    encoding  : options.encoding || (options.multipart ? 'binary' : defaults.encoding)\n  }\n\n  keys_by_type(Boolean).forEach(function(key) {\n    config[key] = check_value('boolean', key);\n  })\n\n  keys_by_type(Number).forEach(function(key) {\n    config[key] = check_value('number', key);\n  })\n\n  if (config.http_opts.signal && !(config.http_opts.signal instanceof AbortSignal))\n    throw new TypeError(typeof config.http_opts.signal + ' received for signal, but expected an AbortSignal');\n\n  // populate http_opts with given TLS options\n  tls_options.split(' ').forEach(function(key) {\n    if (typeof options[key] != 'undefined') {\n      if (config.http_opts.agent) { // pass option to existing agent\n        config.http_opts.agent.options[key] = options[key];\n      } else {\n        config.http_opts[key] = options[key];\n      }\n    }\n  });\n\n  //////////////////////////////////////////////////\n  // headers, cookies\n\n  for (var key in defaults.headers)\n    config.headers[key] = defaults.headers[key];\n\n  config.headers['accept'] = options.accept || defaults.accept;\n  config.headers['user-agent'] = options.user_agent || defaults.user_agent;\n\n  if (options.content_type)\n    config.headers['content-type'] = options.content_type;\n\n  // set connection header if opts.connection was passed, or if node < 0.11.4 (close)\n  if (options.connection || close_by_default)\n    config.headers['connection'] = options.connection || 'close';\n\n  if ((options.compressed || defaults.compressed) && typeof zlib != 'undefined')\n    config.headers['accept-encoding'] = decompressors['br'] ? 'gzip, deflate, br' : 'gzip, deflate';\n\n  if (options.cookies)\n    config.headers['cookie'] = cookies.write(options.cookies);\n\n  //////////////////////////////////////////////////\n  // basic/digest auth\n\n  if (uri.match(/[^\\/]@/)) { // url contains user:pass@host, so parse it.\n    var parts = (url.parse(uri).auth || '').split(':');\n    options.username = parts[0];\n    options.password = parts[1];\n  }\n\n  if (options.username) {\n    if (options.auth && (options.auth == 'auto' || options.auth == 'digest')) {\n      config.credentials = [options.username, options.password];\n    } else {\n      config.headers['authorization'] = auth.basic(options.username, options.password);\n    }\n  }\n\n  if (config.use_proxy_from_env_var) {\n    var env_proxy = utils.get_env_var(['HTTP_PROXY', 'HTTPS_PROXY'], true);\n    if (!config.proxy && env_proxy) config.proxy = env_proxy;\n  }\n\n  // if proxy is present, set auth header from either url or proxy_user option.\n  if (config.proxy) {\n    if (!config.use_proxy_from_env_var || utils.should_proxy_to(uri)) {\n      if (config.proxy.indexOf('http') === -1)\n        config.proxy = 'http://' + config.proxy;\n\n      if (config.proxy.indexOf('@') !== -1) {\n        var proxy = (url.parse(config.proxy).auth || '').split(':');\n        options.proxy_user = proxy[0];\n        options.proxy_pass = proxy[1];\n      }\n\n      if (options.proxy_user)\n        config.headers['proxy-authorization'] = auth.basic(options.proxy_user, options.proxy_pass);\n    } else {\n      delete config.proxy;\n    }\n  }\n\n  // now that all our headers are set, overwrite them if instructed.\n  for (var h in options.headers)\n    config.headers[h.toLowerCase()] = options.headers[h];\n\n  config.uri_modifier = get_option('uri_modifier', null);\n\n  return config;\n}\n\nNeedle.prototype.start = function() {\n\n  var out      = new stream.PassThrough({ objectMode: false }),\n      uri      = this.uri,\n      data     = this.data,\n      method   = this.method,\n      callback = (typeof this.options == 'function') ? this.options : this.callback,\n      options  = this.options || {};\n\n  // if no 'http' is found on URL, prepend it.\n  if (uri.indexOf('http') === -1)\n    uri = uri.replace(/^(\\/\\/)?/, 'http://');\n\n  var self = this, body, waiting = false, config = this.setup(uri, options);\n\n  // unless options.json was set to false, assume boss also wants JSON if content-type matches.\n  var json = options.json || (options.json !== false && config.headers['content-type'] == 'application/json');\n\n  if (data) {\n\n    if (options.multipart) { // boss says we do multipart. so we do it.\n      var boundary = options.boundary || defaults.boundary;\n\n      waiting = true;\n      multipart.build(data, boundary, function(err, parts) {\n        if (err) throw(err);\n\n        config.headers['content-type'] = 'multipart/form-data; boundary=' + boundary;\n        next(parts);\n      });\n\n    } else if (utils.is_stream(data)) {\n\n      if (method == 'get')\n        throw new Error('Refusing to pipe() a stream via GET. Did you mean .post?');\n\n      if (config.stream_length > 0 || (config.stream_length === 0 && data.path)) {\n        // ok, let's get the stream's length and set it as the content-length header.\n        // this prevents some servers from cutting us off before all the data is sent.\n        waiting = true;\n        utils.get_stream_length(data, config.stream_length, function(length) {\n          data.length = length;\n          next(data);\n        })\n\n      } else {\n        // if the boss doesn't want us to get the stream's length, or if it doesn't\n        // have a file descriptor for that purpose, then just head on.\n        body = data;\n      }\n\n    } else if (Buffer.isBuffer(data)) {\n\n      body = data; // use the raw buffer as request body.\n\n    } else if (method == 'get' && !json) {\n\n      // append the data to the URI as a querystring.\n      uri = uri.replace(/\\?.*|$/, '?' + stringify(data));\n\n    } else { // string or object data, no multipart.\n\n      // if string, leave it as it is, otherwise, stringify.\n      body = (typeof(data) === 'string') ? data\n             : json ? JSON.stringify(data) : stringify(data);\n\n      // ensure we have a buffer so bytecount is correct.\n      body = Buffer.from(body, config.encoding);\n    }\n\n  }\n\n  function next(body) {\n    if (body) {\n      if (body.length) config.headers['content-length'] = body.length;\n\n      // if no content-type was passed, determine if json or not.\n      if (!config.headers['content-type']) {\n        config.headers['content-type'] = json\n        ? 'application/json; charset=utf-8'\n        : 'application/x-www-form-urlencoded'; // no charset says W3 spec.\n      }\n    }\n\n    // unless a specific accept header was set, assume json: true wants JSON back.\n    if (options.json && (!options.accept && !(options.headers || {}).accept))\n      config.headers['accept'] = 'application/json';\n\n    self.send_request(1, method, uri, config, body, out, callback);\n  }\n\n  if (!waiting) next(body);\n  return out;\n}\n\nNeedle.prototype.get_request_opts = function(method, uri, config) {\n  var opts      = config.http_opts,\n      proxy     = config.proxy,\n      remote    = proxy ? url.parse(proxy) : url.parse(uri);\n\n  opts.protocol = remote.protocol;\n  opts.host     = remote.hostname;\n  opts.port     = remote.port || (remote.protocol == 'https:' ? 443 : 80);\n  opts.path     = proxy ? uri : remote.pathname + (remote.search || '');\n  opts.method   = method;\n  opts.headers  = config.headers;\n\n  if (!opts.headers['host']) {\n    // if using proxy, make sure the host header shows the final destination\n    var target = proxy ? url.parse(uri) : remote;\n    opts.headers['host'] = target.hostname;\n\n    // and if a non standard port was passed, append it to the port header\n    if (target.port && [80, 443].indexOf(target.port) === -1) {\n      opts.headers['host'] += ':' + target.port;\n    }\n  }\n\n  return opts;\n}\n\nNeedle.prototype.should_follow = function(location, config, original) {\n  if (!location) return false;\n\n  // returns true if location contains matching property (host or protocol)\n  function matches(property) {\n    var property = original[property];\n    return location.indexOf(property) !== -1;\n  }\n\n  // first, check whether the requested location is actually different from the original\n  if (!config.follow_if_same_location && location === original)\n    return false;\n\n  if (config.follow_if_same_host && !matches('host'))\n    return false; // host does not match, so not following\n\n  if (config.follow_if_same_protocol && !matches('protocol'))\n    return false; // procotol does not match, so not following\n\n  return true;\n}\n\nNeedle.prototype.send_request = function(count, method, uri, config, post_data, out, callback) {\n\n  if (typeof config.uri_modifier === 'function') {\n    var modified_uri = config.uri_modifier(uri);\n    debug('Modifying request URI', uri + ' => ' + modified_uri);\n    uri = modified_uri;\n  }\n\n  var request,\n      timer,\n      returned     = 0,\n      self         = this,\n      request_opts = this.get_request_opts(method, uri, config),\n      protocol     = request_opts.protocol == 'https:' ? https : http,\n      signal       = request_opts.signal;\n\n  function done(err, resp) {\n    if (returned++ > 0)\n      return debug('Already finished, stopping here.');\n\n    if (timer) clearTimeout(timer);\n    request.removeListener('error', had_error);\n    out.done = true;\n\n    // An error can still be fired after closing.  In particular, on macOS.\n    // See also:\n    //  - https://github.com/tomas/needle/issues/391\n    //  - https://github.com/less/less.js/issues/3693\n    //  - https://github.com/nodejs/node/issues/27916\n    request.once('error', function() {});\n\n    if (callback)\n      return callback(err, resp, resp ? resp.body : undefined);\n\n    // NOTE: this event used to be called 'end', but the behaviour was confusing\n    // when errors ocurred, because the stream would still emit an 'end' event.\n    out.emit('done', err);\n\n    // trigger the 'done' event on streams we're being piped to, if any\n    var pipes = out._readableState.pipes || [];\n    if (!pipes.forEach) pipes = [pipes];\n    pipes.forEach(function(st) { st.emit('done', err); })\n  }\n\n  function had_error(err) {\n    debug('Request error', err);\n    out.emit('err', err);\n    done(err || new Error('Unknown error when making request.'));\n  }\n\n  function abort_handler() {\n    out.emit('err', new Error('Aborted by signal.'));\n    request.destroy();\n  }\n\n  function set_timeout(type, milisecs) {\n    if (timer) clearTimeout(timer);\n    if (milisecs <= 0) return;\n\n    timer = setTimeout(function() {\n      out.emit('timeout', type);\n      request.destroy();\n      // also invoke done() to terminate job on read_timeout\n      if (type == 'read') done(new Error(type + ' timeout'));\n\n      signal && signal.removeEventListener('abort', abort_handler);\n    }, milisecs);\n  }\n\n  debug('Making request #' + count, request_opts);\n  request = protocol.request(request_opts, function(resp) {\n\n    var headers = resp.headers;\n    debug('Got response', resp.statusCode, headers);\n    out.emit('response', resp);\n\n    set_timeout('read', config.read_timeout);\n\n    // if we got cookies, parse them unless we were instructed not to. make sure to include any\n    // cookies that might have been set on previous redirects.\n    if (config.parse_cookies && (headers['set-cookie'] || config.previous_resp_cookies)) {\n      resp.cookies = extend(config.previous_resp_cookies || {}, cookies.read(headers['set-cookie']));\n      debug('Got cookies', resp.cookies);\n    }\n\n    // if redirect code is found, determine if we should follow it according to the given options.\n    if (redirect_codes.indexOf(resp.statusCode) !== -1 && self.should_follow(headers.location, config, uri)) {\n      // clear timer before following redirects to prevent unexpected setTimeout consequence\n      clearTimeout(timer);\n\n      if (count <= config.follow_max) {\n        out.emit('redirect', headers.location);\n\n        // unless 'follow_keep_method' is true, rewrite the request to GET before continuing.\n        if (!config.follow_keep_method) {\n          method    = 'GET';\n          post_data = null;\n          delete config.headers['content-length']; // in case the original was a multipart POST request.\n        }\n\n        // if follow_set_cookies is true, insert cookies in the next request's headers.\n        // we set both the original request cookies plus any response cookies we might have received.\n        if (config.follow_set_cookies && utils.host_and_ports_match(headers.location, uri)) {\n          var request_cookies = cookies.read(config.headers['cookie']);\n          config.previous_resp_cookies = resp.cookies;\n          if (Object.keys(request_cookies).length || Object.keys(resp.cookies || {}).length) {\n            config.headers['cookie'] = cookies.write(extend(request_cookies, resp.cookies));\n          }\n        } else if (config.headers['cookie']) {\n          debug('Clearing original request cookie', config.headers['cookie']);\n          delete config.headers['cookie'];\n        }\n\n        if (config.follow_set_referer)\n          config.headers['referer'] = encodeURI(uri); // the original, not the destination URL.\n\n        config.headers['host'] = null; // clear previous Host header to avoid conflicts.\n\n        var redirect_url = utils.resolve_url(headers.location, uri);\n        debug('Redirecting to ' +  redirect_url.toString());\n        return self.send_request(++count, method, redirect_url.toString(), config, post_data, out, callback);\n      } else if (config.follow_max > 0) {\n        return done(new Error('Max redirects reached. Possible loop in: ' + headers.location));\n      }\n    }\n\n    // if auth is requested and credentials were not passed, resend request, provided we have user/pass.\n    if (resp.statusCode == 401 && headers['www-authenticate'] && config.credentials) {\n      if (!config.headers['authorization']) { // only if authentication hasn't been sent\n        var auth_header = auth.header(headers['www-authenticate'], config.credentials, request_opts);\n\n        if (auth_header) {\n          config.headers['authorization'] = auth_header;\n          return self.send_request(count, method, uri, config, post_data, out, callback);\n        }\n      }\n    }\n\n    // ok, so we got a valid (non-redirect & authorized) response. let's notify the stream guys.\n    out.emit('header', resp.statusCode, headers);\n    out.emit('headers', headers);\n\n    var pipeline      = [],\n        mime          = utils.parse_content_type(headers['content-type']),\n        text_response = mime.type && (mime.type.indexOf('text/') != -1 || !!mime.type.match(/(\\/|\\+)(xml|json)$/));\n\n    // To start, if our body is compressed and we're able to inflate it, do it.\n    if (headers['content-encoding'] && decompressors[headers['content-encoding']]) {\n\n      var decompressor = decompressors[headers['content-encoding']]();\n\n      // make sure we catch errors triggered by the decompressor.\n      decompressor.on('error', had_error);\n      pipeline.push(decompressor);\n    }\n\n    // If parse is enabled and we have a parser for it, then go for it.\n    if (config.parser && parsers[mime.type]) {\n\n      // If a specific parser was requested, make sure we don't parse other types.\n      var parser_name = config.parser.toString().toLowerCase();\n      if (['xml', 'json'].indexOf(parser_name) == -1 || parsers[mime.type].name == parser_name) {\n\n        // OK, so either we're parsing all content types or the one requested matches.\n        out.parser = parsers[mime.type].name;\n        pipeline.push(parsers[mime.type].fn());\n\n        // Set objectMode on out stream to improve performance.\n        out._writableState.objectMode = true;\n        out._readableState.objectMode = true;\n      }\n\n    // If we're not parsing, and unless decoding was disabled, we'll try\n    // decoding non UTF-8 bodies to UTF-8, using the iconv-lite library.\n    } else if (text_response && config.decode_response && mime.charset) {\n      pipeline.push(decoder(mime.charset));\n    }\n\n    // And `out` is the stream we finally push the decoded/parsed output to.\n    pipeline.push(out);\n\n    // Now, release the kraken!\n    utils.pump_streams([resp].concat(pipeline), function(err) {\n      if (err) debug(err)\n\n      // on node v8.x, if an error ocurrs on the receiving end,\n      // then we want to abort the request to avoid having dangling sockets\n      if (err && err.message == 'write after end') request.destroy();\n    });\n\n    // If the user has requested and output file, pipe the output stream to it.\n    // In stream mode, we will still get the response stream to play with.\n    if (config.output && resp.statusCode == 200) {\n\n      // for some reason, simply piping resp to the writable stream doesn't\n      // work all the time (stream gets cut in the middle with no warning).\n      // so we'll manually need to do the readable/write(chunk) trick.\n      var file = fs.createWriteStream(config.output);\n      file.on('error', had_error);\n\n      out.on('end', function() {\n        if (file.writable) file.end();\n      });\n\n      file.on('close', function() {\n        delete out.file;\n      })\n\n      out.on('readable', function() {\n        var chunk;\n        while ((chunk = this.read()) !== null) {\n          if (file.writable) file.write(chunk);\n\n          // if callback was requested, also push it to resp.body\n          if (resp.body) resp.body.push(chunk);\n        }\n      })\n\n      out.file = file;\n    }\n\n    // Only aggregate the full body if a callback was requested.\n    if (callback) {\n      resp.raw   = [];\n      resp.body  = [];\n      resp.bytes = 0;\n\n      // Gather and count the amount of (raw) bytes using a PassThrough stream.\n      var clean_pipe = new stream.PassThrough();\n\n      clean_pipe.on('readable', function() {\n        var chunk;\n        while ((chunk = this.read()) != null) {\n          resp.bytes += chunk.length;\n          resp.raw.push(chunk);\n        }\n      })\n\n      utils.pump_streams([resp, clean_pipe], function(err) {\n        if (err) debug(err);\n      });\n\n      // Listen on the 'readable' event to aggregate the chunks, but only if\n      // file output wasn't requested. Otherwise we'd have two stream readers.\n      if (!config.output || resp.statusCode != 200) {\n        out.on('readable', function() {\n          var chunk;\n          while ((chunk = this.read()) !== null) {\n            // We're either pushing buffers or objects, never strings.\n            if (typeof chunk == 'string') chunk = Buffer.from(chunk);\n\n            // Push all chunks to resp.body. We'll bind them in resp.end().\n            resp.body.push(chunk);\n          }\n        })\n      }\n    }\n\n    // And set the .body property once all data is in.\n    out.on('end', function() {\n      if (resp.body) { // callback mode\n\n        // we want to be able to access to the raw data later, so keep a reference.\n        resp.raw = Buffer.concat(resp.raw);\n\n        // if parse was successful, we should have an array with one object\n        if (resp.body[0] !== undefined && !Buffer.isBuffer(resp.body[0])) {\n\n          // that's our body right there.\n          resp.body = resp.body[0];\n\n          // set the parser property on our response. we may want to check.\n          if (out.parser) resp.parser = out.parser;\n\n        } else { // we got one or several buffers. string or binary.\n          resp.body = Buffer.concat(resp.body);\n\n          // if we're here and parsed is true, it means we tried to but it didn't work.\n          // so given that we got a text response, let's stringify it.\n          if (text_response || out.parser) {\n            resp.body = resp.body.toString();\n          }\n        }\n      }\n\n      // if an output file is being written to, make sure the callback\n      // is triggered after all data has been written to it.\n      if (out.file) {\n        out.file.on('close', function() {\n          done(null, resp);\n        })\n      } else { // elvis has left the building.\n        done(null, resp);\n      }\n\n    });\n\n    // out.on('error', function(err) {\n    //   had_error(err);\n    //   if (err.code == 'ERR_STREAM_DESTROYED' || err.code == 'ERR_STREAM_PREMATURE_CLOSE') {\n    //     request.abort();\n    //   }\n    // })\n\n  }); // end request call\n\n  // unless open_timeout was disabled, set a timeout to abort the request.\n  set_timeout('open', config.open_timeout);\n\n  // handle errors on the request object. things might get bumpy.\n  request.on('error', had_error);\n\n  // make sure timer is cleared if request is aborted (issue #257)\n  request.once('abort', function() {\n    if (timer) clearTimeout(timer);\n  })\n\n  // set response timeout once we get a valid socket\n  request.once('socket', function(socket) {\n    if (socket.connecting) {\n      socket.once('connect', function() {\n        set_timeout('response', config.response_timeout);\n      })\n    } else {\n      set_timeout('response', config.response_timeout);\n    }\n  })\n\n  if (post_data) {\n    if (utils.is_stream(post_data)) {\n      utils.pump_streams([post_data, request], function(err) {\n        if (err) debug(err);\n      });\n    } else {\n      request.write(post_data, config.encoding);\n      request.end();\n    }\n  } else {\n    request.end();\n  }\n\n  if (signal) { // abort signal given, so handle it\n    if (signal.aborted === true) {\n      abort_handler();\n    } else {\n      signal.addEventListener('abort', abort_handler, { once: true });\n    }\n  }\n\n  out.abort = function() { request.destroy() }; // easier access\n  out.request = request;\n  return out;\n}\n\n//////////////////////////////////////////\n// exports\n\nif (typeof Promise !== 'undefined') {\n  module.exports = function() {\n    var verb, args = [].slice.call(arguments);\n\n    if (args[0].match(/\\.|\\//)) // first argument looks like a URL\n      verb = (args.length > 2) ? 'post' : 'get';\n    else\n      verb = args.shift();\n\n    if (verb.match(/get|head/i) && args.length == 2)\n      args.splice(1, 0, null); // assume no data if head/get with two args (url, options)\n\n    return new Promise(function(resolve, reject) {\n      module.exports.request(verb, args[0], args[1], args[2], function(err, resp) {\n        return err ? reject(err) : resolve(resp);\n      });\n    })\n  }\n}\n\nmodule.exports.version = version;\n\nmodule.exports.defaults = function(obj) {\n  for (var key in obj) {\n    var target_key = aliased.options[key] || key;\n\n    if (defaults.hasOwnProperty(target_key) && typeof obj[key] != 'undefined') {\n      if (target_key != 'parse_response' && target_key != 'proxy' && target_key != 'agent' && target_key != 'signal') {\n        // ensure type matches the original, except for proxy/parse_response that can be null/bool or string, and signal that can be null/AbortSignal\n        var valid_type = defaults[target_key].constructor.name;\n\n        if (obj[key].constructor.name != valid_type)\n          throw new TypeError('Invalid type for ' + key + ', should be ' + valid_type);\n      } else if (target_key === 'signal' && obj[key] !== null && !(obj[key] instanceof AbortSignal)) {\n        throw new TypeError('Invalid type for ' + key + ', should be AbortSignal');\n      }\n      defaults[target_key] = obj[key];\n    } else {\n      throw new Error('Invalid property for defaults:' + target_key);\n    }\n  }\n\n  return defaults;\n}\n\n'head get'.split(' ').forEach(function(method) {\n  module.exports[method] = function(uri, options, callback) {\n    return new Needle(method, uri, null, options, callback).start();\n  }\n})\n\n'post put patch delete'.split(' ').forEach(function(method) {\n  module.exports[method] = function(uri, data, options, callback) {\n    return new Needle(method, uri, data, options, callback).start();\n  }\n})\n\nmodule.exports.request = function(method, uri, data, opts, callback) {\n  return new Needle(method, uri, data, opts, callback).start();\n};\n","// based on the qs module, but handles null objects as expected\n// fixes by Tomas Pollak.\n\nvar toString = Object.prototype.toString;\n\nfunction stringify(obj, prefix) {\n  if (prefix && (obj === null || typeof obj == 'undefined')) {\n    return prefix + '=';\n  } else if (toString.call(obj) == '[object Array]') {\n    return stringifyArray(obj, prefix);\n  } else if (toString.call(obj) == '[object Object]') {\n    return stringifyObject(obj, prefix);\n  } else if (toString.call(obj) == '[object Date]') {\n    return obj.toISOString();\n  } else if (prefix) { // string inside array or hash\n    return prefix + '=' + encodeURIComponent(String(obj));\n  } else if (String(obj).indexOf('=') !== -1) { // string with equal sign\n    return String(obj);\n  } else {\n    throw new TypeError('Cannot build a querystring out of: ' + obj);\n  }\n};\n\nfunction stringifyArray(arr, prefix) {\n  var ret = [];\n\n  for (var i = 0, len = arr.length; i < len; i++) {\n    if (prefix)\n      ret.push(stringify(arr[i], prefix + '[]'));\n    else\n      ret.push(stringify(arr[i]));\n  }\n\n  return ret.join('&');\n}\n\nfunction stringifyObject(obj, prefix) {\n  var ret = [];\n\n  Object.keys(obj).forEach(function(key) {\n    ret.push(stringify(obj[key], prefix\n      ? prefix + '[' + encodeURIComponent(key) + ']'\n      : encodeURIComponent(key)));\n  })\n\n  return ret.join('&');\n}\n\nexports.build = stringify;\n","var readFile = require('fs').readFile,\n    basename = require('path').basename;\n\nexports.build = function(data, boundary, callback) {\n\n  if (typeof data != 'object' || typeof data.pipe == 'function')\n    return callback(new Error('Multipart builder expects data as key/val object.'));\n\n  var body   = '',\n      object = flatten(data),\n      count  = Object.keys(object).length;\n\n  if (count === 0)\n    return callback(new Error('Empty multipart body. Invalid data.'))\n\n  function done(err, section) {\n    if (err) return callback(err);\n    if (section) body += section;\n    --count || callback(null, body + '--' + boundary + '--');\n  };\n\n  for (var key in object) {\n    var value = object[key];\n    if (value === null || typeof value == 'undefined') {\n      done();\n    } else if (Buffer.isBuffer(value)) {\n      var part = { buffer: value, content_type: 'application/octet-stream' };\n      generate_part(key, part, boundary, done);\n    } else {\n      var part = (value.buffer || value.file || value.content_type) ? value : { value: value };\n      generate_part(key, part, boundary, done);\n    }\n  }\n\n}\n\nfunction generate_part(name, part, boundary, callback) {\n\n  var return_part = '--' + boundary + '\\r\\n';\n  return_part += 'Content-Disposition: form-data; name=\"' + name + '\"';\n\n  function append(data, filename) {\n\n    if (data) {\n      var binary = part.content_type.indexOf('text') == -1;\n      return_part += '; filename=\"' + encodeURIComponent(filename) + '\"\\r\\n';\n      if (binary) return_part += 'Content-Transfer-Encoding: binary\\r\\n';\n      return_part += 'Content-Type: ' + part.content_type + '\\r\\n\\r\\n';\n      return_part += binary ? data.toString('binary') : data.toString('utf8');\n    }\n\n    callback(null, return_part + '\\r\\n');\n  };\n\n  if ((part.file || part.buffer) && part.content_type) {\n\n    var filename = part.filename ? part.filename : part.file ? basename(part.file) : name;\n    if (part.buffer) return append(part.buffer, filename);\n\n    readFile(part.file, function(err, data) {\n      if (err) return callback(err);\n      append(data, filename);\n    });\n\n  } else {\n\n    if (typeof part.value == 'object')\n      return callback(new Error('Object received for ' + name + ', expected string.'))\n\n    if (part.content_type) {\n      return_part += '\\r\\n';\n      return_part += 'Content-Type: ' + part.content_type;\n    }\n\n    return_part += '\\r\\n\\r\\n';\n    return_part += Buffer.from(String(part.value), 'utf8').toString('binary');\n    append();\n\n  }\n\n}\n\n// flattens nested objects for multipart body\nfunction flatten(object, into, prefix) {\n  into = into || {};\n\n  for(var key in object) {\n    var prefix_key = prefix ? prefix + '[' + key + ']' : key;\n    var prop = object[key];\n\n    if (prop && typeof prop === 'object' && !(prop.buffer || prop.file || prop.content_type))\n      flatten(prop, into, prefix_key)\n    else\n      into[prefix_key] = prop;\n  }\n\n  return into;\n}\n","var createHash = require('crypto').createHash;\n\nfunction get_header(header, credentials, opts) {\n  var type = header.split(' ')[0],\n      user = credentials[0],\n      pass = credentials[1];\n\n  if (type == 'Digest') {\n    return digest.generate(header, user, pass, opts.method, opts.path);\n  } else if (type == 'Basic') {\n    return basic(user, pass);\n  }\n}\n\n////////////////////\n// basic\n\nfunction md5(string) {\n  return createHash('md5').update(string).digest('hex');\n}\n\nfunction basic(user, pass) {\n  var str  = typeof pass == 'undefined' ? user : [user, pass].join(':');\n  return 'Basic ' + Buffer.from(str).toString('base64');\n}\n\n////////////////////\n// digest\n// logic inspired from https://github.com/simme/node-http-digest-client\n\nvar digest = {};\n\ndigest.parse_header = function(header) {\n  var challenge = {},\n      matches   = header.match(/([a-z0-9_-]+)=\"?([a-z0-9_=\\/\\.@\\s-\\+:)()]+)\"?/gi);\n\n  for (var i = 0, l = matches.length; i < l; i++) {\n    var parts = matches[i].split('='),\n        key   = parts.shift(),\n        val   = parts.join('=').replace(/^\"/, '').replace(/\"$/, '');\n\n    challenge[key] = val;\n  }\n\n  return challenge;\n}\n\ndigest.update_nc = function(nc) {\n  var max = 99999999;\n  nc++;\n\n  if (nc > max)\n    nc = 1;\n\n  var padding = new Array(8).join('0') + '';\n  nc = nc + '';\n  return padding.substr(0, 8 - nc.length) + nc;\n}\n\ndigest.generate = function(header, user, pass, method, path) {\n\n  var nc        = 1,\n      cnonce    = null,\n      challenge = digest.parse_header(header);\n\n  var ha1  = md5(user + ':' + challenge.realm + ':' + pass),\n      ha2  = md5(method.toUpperCase() + ':' + path),\n      resp = [ha1, challenge.nonce];\n\n  if (typeof challenge.qop === 'string') {\n    cnonce = md5(Math.random().toString(36)).substr(0, 8);\n    nc     = digest.update_nc(nc);\n    resp   = resp.concat(nc, cnonce);\n    resp   = resp.concat(challenge.qop, ha2);\n  } else {\n    resp   = resp.concat(ha2);\n  }\n\n  var params = {\n    uri      : path,\n    realm    : challenge.realm,\n    nonce    : challenge.nonce,\n    username : user,\n    response : md5(resp.join(':'))\n  }\n\n  if (challenge.qop) {\n    params.qop = challenge.qop;\n  }\n\n  if (challenge.opaque) {\n    params.opaque = challenge.opaque;\n  }\n\n  if (cnonce) {\n    params.nc = nc;\n    params.cnonce = cnonce;\n  }\n\n  header = []\n  for (var k in params)\n    header.push(k + '=\"' + params[k] + '\"')\n\n  return 'Digest ' + header.join(', ');\n}\n\nmodule.exports = {\n  header : get_header,\n  basic  : basic,\n  digest : digest.generate\n}\n","\n//  Simple cookie handling implementation based on the standard RFC 6265.\n//\n//  This module just has two functionalities:\n//    - Parse a set-cookie-header as a key value object\n//    - Write a cookie-string from a key value object\n//\n//  All cookie attributes are ignored.\n\nvar unescape = require('querystring').unescape;\n\nvar COOKIE_PAIR        = /^([^=\\s]+)\\s*=\\s*(\"?)\\s*(.*)\\s*\\2\\s*$/;\nvar EXCLUDED_CHARS     = /[\\x00-\\x1F\\x7F\\x3B\\x3B\\s\\\"\\,\\\\\"%]/g;\nvar TRAILING_SEMICOLON = /\\x3B+$/;\nvar SEP_SEMICOLON      = /\\s*\\x3B\\s*/;\n\n// i know these should be 'const', but I'd like to keep\n// supporting earlier node.js versions as long as I can. :)\n\nvar KEY_INDEX   = 1; // index of key from COOKIE_PAIR match\nvar VALUE_INDEX = 3; // index of value from COOKIE_PAIR match\n\n// Returns a copy str trimmed and without trainling semicolon.\nfunction cleanCookieString(str) {\n  return str.trim().replace(/\\x3B+$/, '');\n}\n\nfunction getFirstPair(str) {\n  var index = str.indexOf('\\x3B');\n  return index === -1 ? str : str.substr(0, index);\n}\n\n// Returns a encoded copy of str based on RFC6265 S4.1.1.\nfunction encodeCookieComponent(str) {\n  return str.toString().replace(EXCLUDED_CHARS, encodeURIComponent);\n}\n\n// Parses a set-cookie-string based on the standard defined in RFC6265 S4.1.1.\nfunction parseSetCookieString(str) {\n  str = cleanCookieString(str);\n  str = getFirstPair(str);\n\n  var res = COOKIE_PAIR.exec(str);\n  if (!res || !res[VALUE_INDEX]) return null;\n\n  return {\n    name  : unescape(res[KEY_INDEX]),\n    value : unescape(res[VALUE_INDEX])\n  };\n}\n\n// Parses a set-cookie-header and returns a key/value object.\n// Each key represents the name of a cookie.\nfunction parseSetCookieHeader(header) {\n  if (!header) return {};\n  header = Array.isArray(header) ? header : [header];\n\n  return header.reduce(function(res, str) {\n    var cookie = parseSetCookieString(str);\n    if (cookie) res[cookie.name] = cookie.value;\n    return res;\n  }, {});\n}\n\n// Writes a set-cookie-string based on the standard definded in RFC6265 S4.1.1.\nfunction writeCookieString(obj) {\n  return Object.keys(obj).reduce(function(str, name) {\n    var encodedName  = encodeCookieComponent(name);\n    var encodedValue = encodeCookieComponent(obj[name]);\n    str += (str ? '; ' : '') + encodedName + '=' + encodedValue;\n    return str;\n  }, '');\n}\n\n// returns a key/val object from an array of cookie strings\nexports.read = parseSetCookieHeader;\n\n// writes a cookie string header\nexports.write = writeCookieString;\n","//////////////////////////////////////////\n// Defines mappings between content-type\n// and the appropriate parsers.\n//////////////////////////////////////////\n\nvar Transform = require('stream').Transform;\nvar sax = require('sax');\n\nfunction parseXML(str, cb) {\n  var obj, current, parser = sax.parser(true, { trim: true, lowercase: true })\n  parser.onerror = parser.onend = done;\n\n  function done(err) {\n    parser.onerror = parser.onend = function() { }\n    cb(err, obj)\n  }\n\n  function newElement(name, attributes) {\n    return {\n      name: name || '',\n      value: '',\n      attributes: attributes || {},\n      children: []\n    }\n  }\n\n  parser.oncdata = parser.ontext = function(t) {\n    if (current) current.value += t\n  }\n\n  parser.onopentag = function(node) {\n    var element = newElement(node.name, node.attributes)\n    if (current) {\n      element.parent = current\n      current.children.push(element)\n    } else { // root object\n      obj = element\n    }\n\n    current = element\n  };\n\n  parser.onclosetag = function() {\n    if (typeof current.parent !== 'undefined') {\n      var just_closed = current\n      current = current.parent\n      delete just_closed.parent\n    }\n  }\n\n  parser.write(str).close()\n}\n\nfunction parserFactory(name, fn) {\n\n  function parser() {\n    var chunks = [],\n        stream = new Transform({ objectMode: true });\n\n    // Buffer all our data\n    stream._transform = function(chunk, encoding, done) {\n      chunks.push(chunk);\n      done();\n    }\n\n    // And call the parser when all is there.\n    stream._flush = function(done) {\n      var self = this,\n          data = Buffer.concat(chunks);\n\n      try {\n        fn(data, function(err, result) {\n          if (err) throw err;\n          self.push(result);\n        });\n      } catch (err) {\n        self.push(data); // just pass the original data\n      } finally {\n        done();\n      }\n    }\n\n    return stream;\n  }\n\n  return { fn: parser, name: name };\n}\n\nvar parsers = {}\n\nfunction buildParser(name, types, fn) {\n  var parser = parserFactory(name, fn);\n  types.forEach(function(type) {\n    parsers[type] = parser;\n  })\n}\n\nbuildParser('json', [\n  'application/json',\n  'application/hal+json',\n  'text/javascript',\n  'application/vnd.api+json'\n], function(buffer, cb) {\n  var err, data;\n  try { data = JSON.parse(buffer); } catch (e) { err = e; }\n  cb(err, data);\n});\n\nbuildParser('xml', [\n  'text/xml',\n  'application/xml',\n  'application/rdf+xml',\n  'application/rss+xml',\n  'application/atom+xml'\n], function(buffer, cb) {\n  parseXML(buffer.toString(), function(err, obj) {\n    cb(err, obj)\n  })\n});\n\nmodule.exports = parsers;\nmodule.exports.use = buildParser;\n","var iconv,\n    inherits  = require('util').inherits,\n    stream    = require('stream');\n\nvar regex = /(?:charset|encoding)\\s*=\\s*['\"]? *([\\w\\-]+)/i;\n\ninherits(StreamDecoder, stream.Transform);\n\nfunction StreamDecoder(charset) {\n  if (!(this instanceof StreamDecoder))\n    return new StreamDecoder(charset);\n\n  stream.Transform.call(this, charset);\n  this.charset = charset;\n  this.parsed_chunk = false;\n}\n\nStreamDecoder.prototype._transform = function(chunk, encoding, done) {\n  // try to get charset from chunk, but just once\n  if (!this.parsed_chunk && (this.charset == 'utf-8' || this.charset == 'utf8')) {\n    this.parsed_chunk = true;\n\n    var matches = regex.exec(chunk.toString());\n\n    if (matches) {\n      var found = matches[1].toLowerCase().replace('utf8', 'utf-8'); // canonicalize;\n      // set charset, but only if iconv can handle it\n      if (iconv.encodingExists(found)) this.charset = found;\n    }\n  }\n\n  // if charset is already utf-8 or given encoding isn't supported, just pass through\n  if (this.charset == 'utf-8' || !iconv.encodingExists(this.charset)) {\n    this.push(chunk);\n    return done();\n  }\n\n  // initialize stream decoder if not present\n  var self = this;\n  if (!this.decoder) {\n    this.decoder = iconv.decodeStream(this.charset);\n    this.decoder.on('data', function(decoded_chunk) {\n      self.push(decoded_chunk);\n    });\n  };\n\n  this.decoder.write(chunk);\n  done();\n}\n\nmodule.exports = function(charset) {\n  try {\n    if (!iconv) iconv = require('iconv-lite');\n  } catch(e) {\n    /* iconv not found */\n  }\n\n  if (iconv)\n    return new StreamDecoder(charset);\n  else\n    return new stream.PassThrough;\n}\n","var fs = require('fs'),\n    url = require('url'),\n    stream = require('stream');\n\nfunction resolve_url(href, base) {\n  if (url.URL)\n    return new url.URL(href, base);\n\n  // older Node version (< v6.13)\n  return base ? url.resolve(base, href) : href;\n}\n\nfunction host_and_ports_match(url1, url2) {\n  if (url1.indexOf('http') < 0) url1 = 'http://' + url1;\n  if (url2.indexOf('http') < 0) url2 = 'http://' + url2;\n  var a = url.parse(url1), b = url.parse(url2);\n\n  return a.host == b.host\n    && String(a.port || (a.protocol == 'https:' ? 443 : 80))\n    == String(b.port || (b.protocol == 'https:' ? 443 : 80));\n}\n\n// returns false if a no_proxy host or pattern matches given url\nfunction should_proxy_to(uri) {\n  var no_proxy = get_env_var(['NO_PROXY'], true);\n  if (!no_proxy) return true;\n\n  // previous (naive, simple) strategy\n  // var host, hosts = no_proxy.split(',');\n  // for (var i in hosts) {\n  //   host = hosts[i];\n  //   if (host_and_ports_match(host, uri)) {\n  //     return false;\n  //   }\n  // }\n\n  var pattern, pattern_list = no_proxy.split(/[\\s,]+/);\n  for (var i in pattern_list) {\n    pattern = pattern_list[i];\n    if (pattern.trim().length == 0) continue;\n\n    // replace leading dot by asterisk, escape dots and finally replace asterisk by .*\n    var regex = new RegExp(pattern.replace(/^\\./, \"*\").replace(/[.]/g, '\\\\$&').replace(/\\*/g, '.*'))\n    if (uri.match(regex)) return false;\n  }\n\n  return true;\n}\n\nfunction get_env_var(keys, try_lower) {\n  var val, i = -1, env = process.env;\n  while (!val && i < keys.length-1) {\n    val = env[keys[++i]];\n    if (!val && try_lower) {\n      val = env[keys[i].toLowerCase()];\n    }\n  }\n  return val;\n}\n\nfunction parse_content_type(header) {\n  if (!header || header === '') return {};\n\n  var found, charset = 'utf8', arr = header.split(';');\n\n  if (arr.length > 1 && (found = arr[1].match(/charset=(.+)/)))\n    charset = found[1];\n\n  return { type: arr[0], charset: charset };\n}\n\nfunction is_stream(obj) {\n  return typeof obj.pipe === 'function';\n}\n\nfunction get_stream_length(stream, given_length, cb) {\n  if (given_length > 0)\n    return cb(given_length);\n\n  if (stream.end !== void 0 && stream.end !== Infinity && stream.start !== void 0)\n    return cb((stream.end + 1) - (stream.start || 0));\n\n  fs.stat(stream.path, function(err, stat) {\n    cb(stat ? stat.size - (stream.start || 0) : null);\n  });\n}\n\nfunction pump_streams(streams, cb) {\n  if (stream.pipeline)\n    return stream.pipeline.apply(null, streams.concat(cb));\n\n  var tmp = streams.shift();\n  while (streams.length) {\n    tmp = tmp.pipe(streams.shift());\n    tmp.once('error', function(e) {\n      cb && cb(e);\n      cb = null;\n    })\n  }\n}\n\nmodule.exports = {\n  resolve_url: resolve_url,\n  get_env_var: get_env_var,\n  host_and_ports_match: host_and_ports_match,\n  should_proxy_to: should_proxy_to,\n  parse_content_type: parse_content_type,\n  is_stream: is_stream,\n  get_stream_length: get_stream_length,\n  pump_streams: pump_streams\n}","module.exports = {\n  \"name\": \"needle\",\n  \"version\": \"3.3.1\",\n  \"description\": \"The leanest and most handsome HTTP client in the Nodelands.\",\n  \"keywords\": [\n    \"http\",\n    \"https\",\n    \"simple\",\n    \"request\",\n    \"client\",\n    \"multipart\",\n    \"upload\",\n    \"proxy\",\n    \"deflate\",\n    \"timeout\",\n    \"charset\",\n    \"iconv\",\n    \"cookie\",\n    \"redirect\"\n  ],\n  \"tags\": [\n    \"http\",\n    \"https\",\n    \"simple\",\n    \"request\",\n    \"client\",\n    \"multipart\",\n    \"upload\",\n    \"proxy\",\n    \"deflate\",\n    \"timeout\",\n    \"charset\",\n    \"iconv\",\n    \"cookie\",\n    \"redirect\"\n  ],\n  \"author\": \"Tom√°s Pollak <tomas@forkhq.com>\",\n  \"repository\": {\n    \"type\": \"git\",\n    \"url\": \"https://github.com/tomas/needle.git\"\n  },\n  \"dependencies\": {\n    \"iconv-lite\": \"^0.6.3\",\n    \"sax\": \"^1.2.4\"\n  },\n  \"devDependencies\": {\n    \"JSONStream\": \"^1.3.5\",\n    \"jschardet\": \"^1.6.0\",\n    \"mocha\": \"^5.2.0\",\n    \"pump\": \"^3.0.0\",\n    \"q\": \"^1.5.1\",\n    \"should\": \"^13.2.3\",\n    \"sinon\": \"^2.3.0\",\n    \"xml2js\": \"^0.4.19\"\n  },\n  \"scripts\": {\n    \"test\": \"mocha test\"\n  },\n  \"directories\": {\n    \"lib\": \"./lib\"\n  },\n  \"main\": \"./lib/needle\",\n  \"bin\": {\n    \"needle\": \"./bin/needle\"\n  },\n  \"license\": \"MIT\",\n  \"engines\": {\n    \"node\": \">= 4.4.x\"\n  }\n}\n"]}